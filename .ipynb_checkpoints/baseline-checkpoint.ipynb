{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 21), (15000, 20), (15000, 2))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../../train.csv')\n",
    "test = pd.read_csv('../../../test.csv')\n",
    "submit = pd.read_csv('../../../submit.csv')\n",
    "train.shape, test.shape, submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train, test], axis = 0).reset_index(drop = True)\n",
    "#ZHIWU=1数据无意义，剔除该类数据\n",
    "df = df[df['ZHIWU']!=1]\n",
    "#剔除无效指标\n",
    "del df['ZHIWU']\n",
    "del df['XUELI']\n",
    "del df['HYZK']\n",
    "del df['ZHIYE']\n",
    "del df['ZHICHEN']\n",
    "del df['DWYJCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数值类的进行转化：\n",
    "df['GRYJCE'] = df['GRYJCE'] - 237\n",
    "df['GRJCJS'] = df['GRJCJS'] -237 \n",
    "df['GRZHYE'] = df['GRZHYE'] - 237\n",
    "df['GRZHSNJZYE'] = df ['GRZHSNJZYE'] -237\n",
    "df['GRZHDNGJYE'] = (df ['GRZHDNGJYE'] -237)*3\n",
    "df['DKFFE'] = df['DKFFE'] - 237\n",
    "df['DKYE'] = df['DKYE']-237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_2_cols = ['XINGBIE']\n",
    "cate_cols = [ 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "# 记录需要做embedding的变量\n",
    "cEmb = ['DWJJLX','DWSSHY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['missing_rate'] = (df.shape[1] - df.count(axis = 1)) / df.shape[1]\n",
    "\n",
    "\n",
    "#鬼知道，可能反应收入？\n",
    "df['YEARPURINCM'] = df['GRZHYE']-df['GRZHSNJZYE']-df['GRZHDNGJYE']\n",
    "#应还贷款月份，剩余需还贷款月份,已还贷款月份\n",
    "df['HDZYF'] = df['DKFFE']*(df['DKLL']/100+1)/(df['GRYJCE']*2)\n",
    "df['HDSYYF'] = df['DKYE']*(df['DKLL']/100+1)/(df['GRYJCE']*2)\n",
    "df['HDYF'] = (df['DKFFE']-df['DKYE'])/(df['GRYJCE']*2)\n",
    "\n",
    "#应还总额\n",
    "df['HDZYFZE'] = df['DKFFE']*(df['DKLL']/100+1)\n",
    "#待还总额\n",
    "df['HDSYYFZE'] = df['DKYE']*(df['DKLL']/100+1)\n",
    "\n",
    "#特征工程衍生的代码\n",
    "# 图形旋转指标\n",
    "df ['USAGE_RATE']=df['DKYE']/df['DKFFE']\n",
    "df ['USAGE_AMOUNT'] = df['DKFFE']-df['DKYE']\n",
    "df ['GJJRATE'] = (df['GRYJCE'])/df['GRJCJS']\n",
    "\n",
    "# 金额取整指标\n",
    "#df ['DKZS']= df['DKFFE']//100000  \n",
    "#df ['YEZS']= df['DKYE']//100000\n",
    "#df ['ZHZS']= df['GRZHYE']//10000\n",
    "#df ['GJZS']= df['GRZHDNGJYE']//100000\n",
    "#df ['SNZS']= df['GRZHSNJZYE']//10000\n",
    "#df ['YJZS']= df['GRYJCE']//500\n",
    "\n",
    "# 当年提取额\n",
    "df ['WITHDRAW'] =  df ['GRYJCE']*12*2 - df['GRZHDNGJYE']\n",
    "\n",
    "# 上年结转与余额的关系？\n",
    "\n",
    "df['USAGEOVER'] = df['DKYE'] == 0 \n",
    "df['NOUSAGE'] = df['DKYE'] == df['DKFFE']\n",
    "\n",
    "df ['GRZHYE_CMP_GRZHYE'] = df['GRZHYE']/df['GRJCJS'] +df['GRJCJS']*25/12000\n",
    "df ['TOP_USER'] = df['DKFFE'].apply(lambda x: x if (x%50000==0 or x==125000) else 0)\n",
    "df ['TOP_USER1'] = df['DKFFE'].apply(lambda x: 1 if (x%50000==0 or x==125000) else x)\n",
    "\n",
    "gen_feats = [ 'YEARPURINCM','HDZYF',\n",
    "            'HDSYYF','HDYF','HDZYFZE','HDSYYFZE','USAGE_RATE','GJJRATE',\n",
    "             'TOP_USER','TOP_USER1','WITHDRAW','USAGE_AMOUNT'\n",
    "            ]\n",
    " \n",
    "cate_cols += ['USAGEOVER','NOUSAGE','TOP_USER'] #'DKZS','YEZS','ZHZS','GJZS','SNZS','YJZS',\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kde.py:488: RuntimeWarning: invalid value encountered in true_divide\n",
      "  binned = fast_linbin(X, a, b, gridsize) / (delta * nobs)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kdetools.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  FAC1 = 2*(np.pi*bw/RANGE)**2\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fe1b4943550>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 771.875x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df ['g0'] = (df[num_cols[i]]*df[num_cols[j]]).apply(lambda x: math.atan(x))\n",
    "# df ['g0'] = (df[num_cols[i]]-df[num_cols[j]]).apply(lambda x: math.exp(-x*x/10000000000))        \n",
    "import seaborn as sns\n",
    "import math\n",
    "df = df[df['GRZHSNJZYE']==df['GRZHDNGJYE']]\n",
    "sns.pairplot(df[['GRZHDNGJYE','GRZHSNJZYE','GRZHYE','label']],hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    935\n",
       "1.0     21\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRZHDNGJYE</th>\n",
       "      <th>GRZHDNGJYE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600.000</td>\n",
       "      <td>600.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>828.200</td>\n",
       "      <td>828.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6993.020</td>\n",
       "      <td>6993.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2034.295</td>\n",
       "      <td>2034.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-201.220</td>\n",
       "      <td>-201.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>534.800</td>\n",
       "      <td>534.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5648.000</td>\n",
       "      <td>5648.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>813.400</td>\n",
       "      <td>813.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5924.160</td>\n",
       "      <td>5924.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>299.750</td>\n",
       "      <td>299.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2120.720</td>\n",
       "      <td>2120.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4583.700</td>\n",
       "      <td>4583.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-181.680</td>\n",
       "      <td>-181.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-10834.785</td>\n",
       "      <td>-10834.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-103.235</td>\n",
       "      <td>-103.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5279.425</td>\n",
       "      <td>5279.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-11613.870</td>\n",
       "      <td>-11613.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-92.380</td>\n",
       "      <td>-92.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3073.440</td>\n",
       "      <td>3073.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8035.200</td>\n",
       "      <td>8035.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-138199.680</td>\n",
       "      <td>-138199.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>382.000</td>\n",
       "      <td>382.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-8751.270</td>\n",
       "      <td>-8751.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-601.915</td>\n",
       "      <td>-601.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4615.680</td>\n",
       "      <td>4615.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-3368.855</td>\n",
       "      <td>-3368.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>852.765</td>\n",
       "      <td>852.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1599.380</td>\n",
       "      <td>1599.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54955</th>\n",
       "      <td>7917.600</td>\n",
       "      <td>7917.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54956</th>\n",
       "      <td>-10838.510</td>\n",
       "      <td>-10838.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54957</th>\n",
       "      <td>-841.360</td>\n",
       "      <td>-841.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54958</th>\n",
       "      <td>7540.870</td>\n",
       "      <td>7540.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54959</th>\n",
       "      <td>-65.650</td>\n",
       "      <td>-65.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54960</th>\n",
       "      <td>-2304.560</td>\n",
       "      <td>-2304.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54961</th>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54965</th>\n",
       "      <td>6105.640</td>\n",
       "      <td>6105.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54966</th>\n",
       "      <td>2244.480</td>\n",
       "      <td>2244.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54967</th>\n",
       "      <td>-15503.815</td>\n",
       "      <td>-15503.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54968</th>\n",
       "      <td>1304.845</td>\n",
       "      <td>1304.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54969</th>\n",
       "      <td>-8546.720</td>\n",
       "      <td>-8546.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54970</th>\n",
       "      <td>-273.895</td>\n",
       "      <td>-273.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54971</th>\n",
       "      <td>-931.005</td>\n",
       "      <td>-931.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54972</th>\n",
       "      <td>2461.180</td>\n",
       "      <td>2461.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54973</th>\n",
       "      <td>-9.210</td>\n",
       "      <td>-9.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54974</th>\n",
       "      <td>2565.220</td>\n",
       "      <td>2565.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54976</th>\n",
       "      <td>2367.840</td>\n",
       "      <td>2367.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54977</th>\n",
       "      <td>1064.000</td>\n",
       "      <td>1064.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54978</th>\n",
       "      <td>972.800</td>\n",
       "      <td>972.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54979</th>\n",
       "      <td>-1.055</td>\n",
       "      <td>-1.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54980</th>\n",
       "      <td>4966.920</td>\n",
       "      <td>4966.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54981</th>\n",
       "      <td>318.930</td>\n",
       "      <td>318.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54982</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54983</th>\n",
       "      <td>223.720</td>\n",
       "      <td>223.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54985</th>\n",
       "      <td>-95.390</td>\n",
       "      <td>-95.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54992</th>\n",
       "      <td>2750.860</td>\n",
       "      <td>2750.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54993</th>\n",
       "      <td>-13725.915</td>\n",
       "      <td>-13725.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54995</th>\n",
       "      <td>916.800</td>\n",
       "      <td>916.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54998</th>\n",
       "      <td>3971.400</td>\n",
       "      <td>3971.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49994 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GRZHDNGJYE  GRZHDNGJYE\n",
       "0         600.000     600.000\n",
       "1         828.200     828.200\n",
       "2        6993.020    6993.020\n",
       "3        2034.295    2034.295\n",
       "4        -201.220    -201.220\n",
       "5         534.800     534.800\n",
       "6        5648.000    5648.000\n",
       "7         813.400     813.400\n",
       "8        5924.160    5924.160\n",
       "9         299.750     299.750\n",
       "10       2120.720    2120.720\n",
       "11       4583.700    4583.700\n",
       "12       -181.680    -181.680\n",
       "13     -10834.785  -10834.785\n",
       "14       -103.235    -103.235\n",
       "15       5279.425    5279.425\n",
       "16     -11613.870  -11613.870\n",
       "17        -92.380     -92.380\n",
       "18       3073.440    3073.440\n",
       "19       8035.200    8035.200\n",
       "20    -138199.680 -138199.680\n",
       "21        382.000     382.000\n",
       "22      -8751.270   -8751.270\n",
       "23          0.000       0.000\n",
       "24       -601.915    -601.915\n",
       "25       4615.680    4615.680\n",
       "26      -3368.855   -3368.855\n",
       "27        852.765     852.765\n",
       "28       1250.000    1250.000\n",
       "29       1599.380    1599.380\n",
       "...           ...         ...\n",
       "54955    7917.600    7917.600\n",
       "54956  -10838.510  -10838.510\n",
       "54957    -841.360    -841.360\n",
       "54958    7540.870    7540.870\n",
       "54959     -65.650     -65.650\n",
       "54960   -2304.560   -2304.560\n",
       "54961     400.000     400.000\n",
       "54965    6105.640    6105.640\n",
       "54966    2244.480    2244.480\n",
       "54967  -15503.815  -15503.815\n",
       "54968    1304.845    1304.845\n",
       "54969   -8546.720   -8546.720\n",
       "54970    -273.895    -273.895\n",
       "54971    -931.005    -931.005\n",
       "54972    2461.180    2461.180\n",
       "54973      -9.210      -9.210\n",
       "54974    2565.220    2565.220\n",
       "54976    2367.840    2367.840\n",
       "54977    1064.000    1064.000\n",
       "54978     972.800     972.800\n",
       "54979      -1.055      -1.055\n",
       "54980    4966.920    4966.920\n",
       "54981     318.930     318.930\n",
       "54982       0.000       0.000\n",
       "54983     223.720     223.720\n",
       "54985     -95.390     -95.390\n",
       "54992    2750.860    2750.860\n",
       "54993  -13725.915  -13725.915\n",
       "54995     916.800     916.800\n",
       "54998    3971.400    3971.400\n",
       "\n",
       "[49994 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['GRZHDNGJYE','GRZHDNGJYE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(df,col = 'age'):\n",
    "    df[col+\"_genFeat1\"]=(df['age'] > 18).astype(int)\n",
    "    df[col+\"_genFeat2\"]=(df['age'] > 25).astype(int)\n",
    "    df[col+\"_genFeat3\"]=(df['age'] > 30).astype(int)\n",
    "    df[col+\"_genFeat4\"]=(df['age'] > 35).astype(int)\n",
    "    df[col+\"_genFeat5\"]=(df['age'] > 40).astype(int)\n",
    "    df[col+\"_genFeat6\"]=(df['age'] > 45).astype(int)\n",
    "    return df, [col + f'_genFeat{i}' for i in range(1, 7)]\n",
    "\n",
    "tNow = time.mktime(time.strptime( '2021-01-12 00:00:00','%Y-%m-%d %H:%M:%S'))\n",
    "#这个怎么换算出来的啊，超哥\n",
    "df['age'] = ((1609430399 - df['CSNY']) / (365 * 24 * 3600)).astype(int)\n",
    "df['bornmonth'] = df['CSNY'].apply(lambda x: time.localtime(x)[1])\n",
    "df, genFeats1 = get_age(df, col = 'age')\n",
    "\n",
    "# More indics -- age \n",
    "\n",
    "#sns.distplot(df['age'][df['age'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_daikuanYE(df,col):\n",
    "    df[col + '_genFeat1'] = (df[col] > 100000).astype(int)\n",
    "    df[col + '_genFeat2'] = (df[col] > 120000).astype(int)\n",
    "    df[col + '_genFeat3'] = (df[col] > 140000).astype(int)\n",
    "    df[col + '_genFeat4'] = (df[col] > 180000).astype(int)\n",
    "    df[col + '_genFeat5'] = (df[col] > 220000).astype(int)\n",
    "    df[col + '_genFeat6'] = (df[col] > 260000).astype(int)\n",
    "    df[col + '_genFeat7'] = (df[col] > 300000).astype(int)\n",
    "    return df, [col + f'_genFeat{i}' for i in range(1, 8)]\n",
    "\n",
    "df, genFeats2 = get_daikuanYE(df, col = 'DKYE')\n",
    "df, genFeats3 = get_daikuanYE(df, col = 'DKFFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 42.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 127.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.30it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 34.47it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 106.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# One-hot 编码\n",
    "for f in tqdm(cate_cols):\n",
    "    df[f] = df[f].map(dict(zip(df[f].unique(), range(df[f].nunique()))))\n",
    "    df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "    df = pd.concat([df,pd.get_dummies(df[f],prefix=f\"{f}\")],axis=1)\n",
    "\n",
    "#离散型特征关联\n",
    "cate_cols_combine = [[cate_cols[i], cate_cols[j]] for i in range(len(cate_cols)) \\\n",
    "                     for j in range(i + 1, len(cate_cols))]\n",
    "\n",
    "#离散型联合计数占比\n",
    "for f1, f2 in tqdm(cate_cols_combine):\n",
    "    df['{}_{}_count'.format(f1, f2)] = df.groupby([f1, f2])['id'].transform('count')\n",
    "    df['{}_in_{}_prop'.format(f1, f2)] = df['{}_{}_count'.format(f1, f2)] / df[f2 + '_count']\n",
    "    df['{}_in_{}_prop'.format(f2, f1)] = df['{}_{}_count'.format(f1, f2)] / df[f1 + '_count']\n",
    "\n",
    "\n",
    "#离散型变量下各个数值型指标统计\n",
    "for f1 in tqdm(cate_cols):\n",
    "    g = df.groupby(f1)\n",
    "    for f2 in num_cols + gen_feats:\n",
    "        for stat in ['sum', 'mean', 'std', 'max', 'min', 'std']:\n",
    "            if '{}_{}_{}'.format(f1, f2, stat)  in validIndics:\n",
    "                df['{}_{}_{}'.format(f1, f2, stat)] = g[f2].transform(stat)\n",
    "    for f3 in genFeats2 + genFeats3:\n",
    "        for stat in ['sum', 'mean']:\n",
    "            if '{}_{}_{}'.format(f1, f3, stat) in validIndics:\n",
    "                df['{}_{}_{}'.format(f1, f3, stat)] = g[f3].transform(stat)\n",
    "\n",
    "    \n",
    "#离散型变量下各个数值特征指标\n",
    "num_cols_gen_feats = num_cols + gen_feats\n",
    "for f1 in tqdm(num_cols_gen_feats):\n",
    "    g = df.groupby(f1)\n",
    "    for f2 in num_cols_gen_feats:\n",
    "        if f1 != f2:\n",
    "            for stat in ['sum', 'mean', 'std', 'max', 'min', 'std']:\n",
    "                if '{}_{}_{}'.format(f1, f2, stat) in validIndics:\n",
    "                    df['{}_{}_{}'.format(f1, f2, stat)] = g[f2].transform(stat)\n",
    "\n",
    "#连续性数值间的特征工程\n",
    "for i in tqdm(range(len(num_cols_gen_feats))):\n",
    "    for j in range(i + 1, len(num_cols_gen_feats)):\n",
    "        if f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_add'  in validIndics:\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_add'] = df[num_cols_gen_feats[i]] + df[num_cols_gen_feats[j]]\n",
    "        if f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_diff'  in validIndics:\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_diff'] = df[num_cols_gen_feats[i]] - df[num_cols_gen_feats[j]]\n",
    "        if f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_multi'  in validIndics:\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_multi'] = df[num_cols_gen_feats[i]] * df[num_cols_gen_feats[j]]\n",
    "        if f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_div'  in validIndics:\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_div'] = df[num_cols_gen_feats[i]] / (df[num_cols_gen_feats[j]] + 0.0000000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39994, 422)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 422)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = df[df['label'].isna() == False].reset_index(drop=True)\n",
    "test_df = df[df['label'].isna() == True].reset_index(drop=True)\n",
    "display(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 连续值的woe分箱处理\n",
    "#import scorecardpy as sc\n",
    "#bins_0 = sc.woebin(train_df[validIndics+['label']], y=\"label\")\n",
    "#train_df = pd.merge(train_df,sc.woebin_ply(train_df, bins_0)[[i+'_woe' for i in validIndics if i+'_woe' in validIndicsRw]+['id']  ],how='left',on='id')\n",
    "#test_df = pd.merge(test_df,sc.woebin_ply(test_df, bins_0)[[i+'_woe'  for i in validIndics if i+'_woe' in validIndicsRw ]+['id']  ],how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, ['missing_rate'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_feats = []\n",
    "drop_feats = [f for f in train_df.columns if train_df[f].nunique() == 1 or train_df[f].nunique() == 0]\n",
    "len(drop_feats), drop_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [col for col in train_df.columns if col not in ['id', 'label'] + drop_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XINGBIE</th>\n",
       "      <th>CSNY</th>\n",
       "      <th>DWJJLX</th>\n",
       "      <th>DWSSHY</th>\n",
       "      <th>GRJCJS</th>\n",
       "      <th>GRZHZT</th>\n",
       "      <th>GRZHYE</th>\n",
       "      <th>GRZHSNJZYE</th>\n",
       "      <th>GRZHDNGJYE</th>\n",
       "      <th>GRYJCE</th>\n",
       "      <th>...</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHDNGJYE_HDYF_multi</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHDNGJYE_HDYF_div</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHSNJZYE_YEARPURINCM_multi</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHSNJZYE_YEARPURINCM_div</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHSNJZYE_HDSYYF_multi</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHSNJZYE_HDYF_multi</th>\n",
       "      <th>numsOf_GRZHYE_diff_GRZHSNJZYE_HDYF_div</th>\n",
       "      <th>numsOf_YEARPURINCM_HDZYF_multi</th>\n",
       "      <th>numsOf_YEARPURINCM_HDSYYF_multi</th>\n",
       "      <th>numsOf_YEARPURINCM_HDYF_multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39994.000000</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>39994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "      <td>3.999400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.361904</td>\n",
       "      <td>4.804880e+08</td>\n",
       "      <td>1.955268</td>\n",
       "      <td>6.834200</td>\n",
       "      <td>4270.991214</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>14783.907521</td>\n",
       "      <td>15081.729709</td>\n",
       "      <td>-354.089497</td>\n",
       "      <td>449.982701</td>\n",
       "      <td>...</td>\n",
       "      <td>5.268634e+05</td>\n",
       "      <td>5.029838e+12</td>\n",
       "      <td>1.849031e+08</td>\n",
       "      <td>1.930774e+10</td>\n",
       "      <td>-1.851914e+05</td>\n",
       "      <td>-7.854554e+04</td>\n",
       "      <td>2.052774e+12</td>\n",
       "      <td>-2.993560e+04</td>\n",
       "      <td>4.950440e+04</td>\n",
       "      <td>-7.723499e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480869</td>\n",
       "      <td>9.752510e+08</td>\n",
       "      <td>2.932171</td>\n",
       "      <td>4.663459</td>\n",
       "      <td>2844.718828</td>\n",
       "      <td>0.092717</td>\n",
       "      <td>20191.323425</td>\n",
       "      <td>20061.923016</td>\n",
       "      <td>7969.029462</td>\n",
       "      <td>344.940588</td>\n",
       "      <td>...</td>\n",
       "      <td>1.437513e+06</td>\n",
       "      <td>4.777124e+13</td>\n",
       "      <td>1.177055e+09</td>\n",
       "      <td>2.750951e+12</td>\n",
       "      <td>4.175485e+06</td>\n",
       "      <td>1.301632e+06</td>\n",
       "      <td>2.465904e+13</td>\n",
       "      <td>4.326874e+06</td>\n",
       "      <td>3.705045e+06</td>\n",
       "      <td>1.207944e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.150720e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-240555.745000</td>\n",
       "      <td>9.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.075000e+06</td>\n",
       "      <td>-9.429696e+02</td>\n",
       "      <td>-7.592296e+09</td>\n",
       "      <td>-1.546324e+04</td>\n",
       "      <td>-1.138616e+08</td>\n",
       "      <td>-4.566406e+07</td>\n",
       "      <td>-1.580725e+15</td>\n",
       "      <td>-1.707478e+08</td>\n",
       "      <td>-1.209340e+08</td>\n",
       "      <td>-4.850042e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.391776e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1655.228750</td>\n",
       "      <td>2761.678750</td>\n",
       "      <td>-814.293750</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.840133e+04</td>\n",
       "      <td>5.083629e+01</td>\n",
       "      <td>1.033832e+06</td>\n",
       "      <td>7.986862e-01</td>\n",
       "      <td>-7.551387e+05</td>\n",
       "      <td>-6.689386e+04</td>\n",
       "      <td>-1.386574e+02</td>\n",
       "      <td>-4.781471e+05</td>\n",
       "      <td>-3.057307e+05</td>\n",
       "      <td>-3.990270e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.205276e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3650.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8305.872500</td>\n",
       "      <td>8777.247500</td>\n",
       "      <td>534.800000</td>\n",
       "      <td>379.830000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.160881e+05</td>\n",
       "      <td>3.808753e+02</td>\n",
       "      <td>1.544043e+07</td>\n",
       "      <td>1.228357e+00</td>\n",
       "      <td>1.302089e+05</td>\n",
       "      <td>7.187333e+03</td>\n",
       "      <td>1.796958e+01</td>\n",
       "      <td>3.988772e+05</td>\n",
       "      <td>2.067019e+05</td>\n",
       "      <td>9.027988e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.338016e+08</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5594.406250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19361.463750</td>\n",
       "      <td>19335.523750</td>\n",
       "      <td>2216.092500</td>\n",
       "      <td>612.105000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.444996e+05</td>\n",
       "      <td>2.133793e+03</td>\n",
       "      <td>9.504473e+07</td>\n",
       "      <td>1.392637e+00</td>\n",
       "      <td>1.576738e+06</td>\n",
       "      <td>9.241615e+04</td>\n",
       "      <td>4.108345e+02</td>\n",
       "      <td>1.688361e+06</td>\n",
       "      <td>1.504453e+06</td>\n",
       "      <td>7.739312e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.903646e+11</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13455.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>366414.575000</td>\n",
       "      <td>313111.420000</td>\n",
       "      <td>52828.095000</td>\n",
       "      <td>1508.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.010184e+07</td>\n",
       "      <td>1.876980e+15</td>\n",
       "      <td>6.446119e+10</td>\n",
       "      <td>5.105143e+14</td>\n",
       "      <td>9.277091e+07</td>\n",
       "      <td>1.980470e+07</td>\n",
       "      <td>7.171058e+14</td>\n",
       "      <td>9.927211e+07</td>\n",
       "      <td>9.894531e+07</td>\n",
       "      <td>2.268783e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            XINGBIE          CSNY        DWJJLX        DWSSHY        GRJCJS  \\\n",
       "count  39994.000000  3.999400e+04  39994.000000  39994.000000  39994.000000   \n",
       "mean       1.361904  4.804880e+08      1.955268      6.834200   4270.991214   \n",
       "std        0.480869  9.752510e+08      2.932171      4.663459   2844.718828   \n",
       "min        0.000000  3.150720e+07      0.000000      0.000000    550.000000   \n",
       "25%        1.000000  3.391776e+08      0.000000      3.000000   2125.000000   \n",
       "50%        1.000000  5.205276e+08      1.000000      6.000000   3650.500000   \n",
       "75%        2.000000  6.338016e+08      2.000000     10.000000   5594.406250   \n",
       "max        2.000000  1.903646e+11     27.000000     20.000000  13455.000000   \n",
       "\n",
       "             GRZHZT         GRZHYE     GRZHSNJZYE     GRZHDNGJYE  \\\n",
       "count  39994.000000   39994.000000   39994.000000   39994.000000   \n",
       "mean       0.005476   14783.907521   15081.729709    -354.089497   \n",
       "std        0.092717   20191.323425   20061.923016    7969.029462   \n",
       "min        0.000000       0.000000       0.000000 -240555.745000   \n",
       "25%        0.000000    1655.228750    2761.678750    -814.293750   \n",
       "50%        0.000000    8305.872500    8777.247500     534.800000   \n",
       "75%        0.000000   19361.463750   19335.523750    2216.092500   \n",
       "max        4.000000  366414.575000  313111.420000   52828.095000   \n",
       "\n",
       "             GRYJCE  ...  numsOf_GRZHYE_diff_GRZHDNGJYE_HDYF_multi  \\\n",
       "count  39994.000000  ...                              3.999400e+04   \n",
       "mean     449.982701  ...                              5.268634e+05   \n",
       "std      344.940588  ...                              1.437513e+06   \n",
       "min        9.550000  ...                             -3.075000e+06   \n",
       "25%      174.000000  ...                              2.840133e+04   \n",
       "50%      379.830000  ...                              1.160881e+05   \n",
       "75%      612.105000  ...                              4.444996e+05   \n",
       "max     1508.940000  ...                              6.010184e+07   \n",
       "\n",
       "       numsOf_GRZHYE_diff_GRZHDNGJYE_HDYF_div  \\\n",
       "count                            3.999400e+04   \n",
       "mean                             5.029838e+12   \n",
       "std                              4.777124e+13   \n",
       "min                             -9.429696e+02   \n",
       "25%                              5.083629e+01   \n",
       "50%                              3.808753e+02   \n",
       "75%                              2.133793e+03   \n",
       "max                              1.876980e+15   \n",
       "\n",
       "       numsOf_GRZHYE_diff_GRZHSNJZYE_YEARPURINCM_multi  \\\n",
       "count                                     3.999400e+04   \n",
       "mean                                      1.849031e+08   \n",
       "std                                       1.177055e+09   \n",
       "min                                      -7.592296e+09   \n",
       "25%                                       1.033832e+06   \n",
       "50%                                       1.544043e+07   \n",
       "75%                                       9.504473e+07   \n",
       "max                                       6.446119e+10   \n",
       "\n",
       "       numsOf_GRZHYE_diff_GRZHSNJZYE_YEARPURINCM_div  \\\n",
       "count                                   3.999400e+04   \n",
       "mean                                    1.930774e+10   \n",
       "std                                     2.750951e+12   \n",
       "min                                    -1.546324e+04   \n",
       "25%                                     7.986862e-01   \n",
       "50%                                     1.228357e+00   \n",
       "75%                                     1.392637e+00   \n",
       "max                                     5.105143e+14   \n",
       "\n",
       "       numsOf_GRZHYE_diff_GRZHSNJZYE_HDSYYF_multi  \\\n",
       "count                                3.999400e+04   \n",
       "mean                                -1.851914e+05   \n",
       "std                                  4.175485e+06   \n",
       "min                                 -1.138616e+08   \n",
       "25%                                 -7.551387e+05   \n",
       "50%                                  1.302089e+05   \n",
       "75%                                  1.576738e+06   \n",
       "max                                  9.277091e+07   \n",
       "\n",
       "       numsOf_GRZHYE_diff_GRZHSNJZYE_HDYF_multi  \\\n",
       "count                              3.999400e+04   \n",
       "mean                              -7.854554e+04   \n",
       "std                                1.301632e+06   \n",
       "min                               -4.566406e+07   \n",
       "25%                               -6.689386e+04   \n",
       "50%                                7.187333e+03   \n",
       "75%                                9.241615e+04   \n",
       "max                                1.980470e+07   \n",
       "\n",
       "       numsOf_GRZHYE_diff_GRZHSNJZYE_HDYF_div  numsOf_YEARPURINCM_HDZYF_multi  \\\n",
       "count                            3.999400e+04                    3.999400e+04   \n",
       "mean                             2.052774e+12                   -2.993560e+04   \n",
       "std                              2.465904e+13                    4.326874e+06   \n",
       "min                             -1.580725e+15                   -1.707478e+08   \n",
       "25%                             -1.386574e+02                   -4.781471e+05   \n",
       "50%                              1.796958e+01                    3.988772e+05   \n",
       "75%                              4.108345e+02                    1.688361e+06   \n",
       "max                              7.171058e+14                    9.927211e+07   \n",
       "\n",
       "       numsOf_YEARPURINCM_HDSYYF_multi  numsOf_YEARPURINCM_HDYF_multi  \n",
       "count                     3.999400e+04                   3.999400e+04  \n",
       "mean                      4.950440e+04                  -7.723499e+04  \n",
       "std                       3.705045e+06                   1.207944e+06  \n",
       "min                      -1.209340e+08                  -4.850042e+07  \n",
       "25%                      -3.057307e+05                  -3.990270e+04  \n",
       "50%                       2.067019e+05                   9.027988e+03  \n",
       "75%                       1.504453e+06                   7.739312e+04  \n",
       "max                       9.894531e+07                   2.268783e+07  \n",
       "\n",
       "[8 rows x 421 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 利用神经网络做embedding以及特征工程 \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras 神经网络生成器\n",
    "# 只采用需要进行embedding的变量，后续优化应该加入其他连续或者分类变量\n",
    "def build_embedding_network(rawsize,embedingsize,densesize):\n",
    "    inputs = []\n",
    "    embeddings = []\n",
    "    \n",
    "    # 离散变量\n",
    "    for i in range(len(rawsize)):\n",
    "        input_cate_feature = Input(shape=(1,))\n",
    "        embedding = Embedding(rawsize[i], embedingsize[i], input_length=1)(input_cate_feature)\n",
    "        embedding = Reshape(target_shape=(embedingsize[i],))(embedding)\n",
    "        inputs.append(input_cate_feature)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    # 连续变量\n",
    "    input_numeric = Input(shape=(densesize,))\n",
    "    embedding_numeric = Dense(100,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(input_numeric) \n",
    "    inputs.append(input_numeric)\n",
    "    embeddings.append(embedding_numeric)\n",
    "    \n",
    "    if len(rawsize) >0:\n",
    "        x = Concatenate()(embeddings)\n",
    "        x = Dense(50,kernel_initializer='uniform', activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(x)\n",
    "    else:\n",
    "        x = Dense(50,kernel_initializer='uniform', activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(embedding_numeric)\n",
    "    x = Dropout(.15)(x)\n",
    "    x = Dense(20,kernel_initializer='uniform', activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(x)\n",
    "    x = Dropout(.15)(x)\n",
    "    x = Dense(10,kernel_initializer='uniform', activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(x)\n",
    "    x = Dropout(.15)(x)\n",
    "    x = Dense(5,kernel_initializer='uniform', activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(x)\n",
    "    x = Dropout(.15)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    sgd = optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-da43addab47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_data_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minput_data_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    369\u001b[0m         X = self._validate_data(X, reset=first_pass,\n\u001b[1;32m    370\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                                 force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 645\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n\u001b[0;32m---> 99\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    100\u001b[0m             )\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "input_data = []\n",
    "input_data_test = []\n",
    "mms.fit(train_df[cols].values)\n",
    "input_data.append(mms.transform(train_df[cols].values))\n",
    "input_data_test.append(mms.transform(test_df[cols].values))\n",
    "kerasModel = build_embedding_network([],[],len(cols))\n",
    "output_data = train_df['label'].values\n",
    "history = kerasModel.fit(input_data, output_data, epochs=100, batch_size=1000,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f874a88b390>]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-119a8c1724e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     intermediate_layer_model = Model(inputs=kerasModel.input,\n\u001b[1;32m      5\u001b[0m                                      outputs=kerasModel.get_layer(kerasModel.get_config()['layers'][layer]['name']).output)\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mencoding_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mencoding_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'KERAS_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mcan_handle\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    617\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m     \u001b[0mhandles_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0mhandles_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_is_list_of_scalars\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Build a new model for embedding\n",
    "for layer in [8]:\n",
    "    print (kerasModel.get_config()['layers'][layer]['name'])\n",
    "    intermediate_layer_model = Model(inputs=kerasModel.input,\n",
    "                                     outputs=kerasModel.get_layer(kerasModel.get_config()['layers'][layer]['name']).output)\n",
    "    encoding_result = pd.DataFrame(intermediate_layer_model.predict(input_data))\n",
    "    encoding_result.columns = ['KERAS_'+str(layer)+\"_\"+str(i) for i in encoding_result.columns]\n",
    "    train_df = pd.concat([train_df,encoding_result],axis=1)\n",
    "    \n",
    "    encoding_result = pd.DataFrame(intermediate_layer_model.predict(input_data_test))\n",
    "    encoding_result.columns = ['KERAS_'+str(layer)+\"_\"+str(i) for i in encoding_result.columns]\n",
    "    test_df = pd.concat([test_df,encoding_result],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [col for col in train_df.columns if col not in ['id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "import time\n",
    "from lightgbm.callback import reset_parameter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    \n",
    "    return ('TPR',0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3,True)\n",
    "\n",
    "def AUC_PRE(y_true,y_predict):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    from sklearn.metrics import auc\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_predict)\n",
    "    auc_score = auc(recall, precision)   \n",
    "    return ('AUC_PRE',auc_score,True)\n",
    "\n",
    "def f1_loss(y, pred):\n",
    "    beta = 2\n",
    "    p = 1. / (1 + np.exp(-pred))\n",
    "    grad = p * ((beta - 1) * y + 1) - beta * y\n",
    "    hess = ((beta - 1) * y + 1) * p * (1.0 - p)\n",
    " \n",
    "    return grad, hess\n",
    "def logistic_obj(y_hat, pred):\n",
    "    y = pred\n",
    "    p = y_hat \n",
    "    p = 1. / (1. + np.exp(-y_hat)) # 用于避免hessian矩阵中很多0\n",
    "    grad = p - y\n",
    "    hess = p * (1. - p)\n",
    "    grad = 4 * p * y + p - 5 * y\n",
    "    hess = (4 * y + 1) * (p * (1.0 - p))\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "--------------------- 0rd fold ---------------------\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_error: 0.0416302\n",
      "[400]\tvalid_0's binary_error: 0.0356295\n",
      "[600]\tvalid_0's binary_error: 0.0338792\n",
      "[800]\tvalid_0's binary_error: 0.0328791\n",
      "Early stopping, best iteration is:\n",
      "[739]\tvalid_0's binary_error: 0.0326291\n",
      "--------------------- 1rd fold ---------------------\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_error: 0.0411301\n",
      "[400]\tvalid_0's binary_error: 0.0325041\n",
      "[600]\tvalid_0's binary_error: 0.031879\n",
      "Early stopping, best iteration is:\n",
      "[547]\tvalid_0's binary_error: 0.0311289\n",
      "--------------------- 2rd fold ---------------------\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_error: 0.0465058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-85795586201e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0;31m#      callbacks = [reset_parameter(**reset_parameters)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    677\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    471\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "oof = np.zeros(train_df.shape[0])\n",
    "feat_imp_df = pd.DataFrame({'feat': cols, 'imp': 0})\n",
    "test_df['prob'] = 0\n",
    "clf = LGBMClassifier(\n",
    "    boosting_type = 'gbdt',\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=2023,\n",
    "    num_leaves=101,\n",
    " #   max_depth = 20,\n",
    "    random_state=1023,\n",
    "    metric=None,\n",
    "    is_unbalance=True,\n",
    "    reg_alpha=0.01,\n",
    "    reg_lambda=0.01,\n",
    "    bagging_freq = 10,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.8,\n",
    "    min_data_in_leaf = 10,\n",
    ")\n",
    "reset_parameters = {\n",
    "    'learning_rate' : [ 0.05*math.exp(-0.005*i) for i in range(2023)]\n",
    "}\n",
    "\n",
    "modellist = []\n",
    "val_aucs = []\n",
    "seeds = [1023]\n",
    "for seed in seeds:\n",
    "    print(seed)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    for i, (trn_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "        print('--------------------- {}rd fold ---------------------'.format(i))\n",
    "        t = time.time()\n",
    "        trn_x, trn_y = train_df[cols].iloc[trn_idx].reset_index(drop=True), train_df['label'].values[trn_idx]\n",
    "        val_x, val_y = train_df[cols].iloc[val_idx].reset_index(drop=True), train_df['label'].values[val_idx]\n",
    "        clf.fit(\n",
    "            trn_x, trn_y,\n",
    "            eval_set=[(val_x, val_y)],\n",
    "       #      categorical_feature=cate_cols,\n",
    "            eval_metric='binary_error',\n",
    "            early_stopping_rounds=200,\n",
    "            verbose=200,\n",
    "      #      callbacks = [reset_parameter(**reset_parameters)]\n",
    "        )\n",
    "        modellist.append(clf)\n",
    "        feat_imp_df['imp'] += clf.feature_importances_ / skf.n_splits\n",
    "        oof[val_idx] = clf.predict_proba(val_x)[:, 1]\n",
    "        test_df['prob'] += clf.predict_proba(test_df[cols])[:, 1] / skf.n_splits / len(seeds)\n",
    "\n",
    "    cv_auc = roc_auc_score(train_df['label'], oof)\n",
    "    val_aucs.append(cv_auc)\n",
    "    print('\\ncv_auc: ', cv_auc)\n",
    "print(val_aucs, np.mean(val_aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    train_df[cols],train_df['label'],\n",
    "       #      categorical_feature=cate_cols,\n",
    "            eval_metric=tpr_weight_funtion,\n",
    "       #     early_stopping_rounds=200,\n",
    "           verbose=200,\n",
    "        #    callbacks = [reset_parameter(**reset_parameters)]\n",
    "        )\n",
    "test_df['prob'] += clf.predict_proba(test_df[cols])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9354490502945435] 0.9354490502945435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.529489, 0.93545)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_aucs, np.mean(val_aucs))\n",
    "tpr = round(tpr_weight_funtion(train_df['label'], oof)[1], 6)\n",
    "tpr, round(np.mean(val_aucs), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#指标重要性分析\n",
    "dImp = pd.DataFrame({\n",
    "        'column': cols,\n",
    "        'importance': [sum(i)/len(i) for i in np.array([ i.feature_importances_ for i in modellist ]).transpose()] ,\n",
    "    }).sort_values(by='importance',ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dImp.to_csv('Feature_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numsOf_GRJCJS_GRYJCE_div', 'DWJJLX_in_DWSSHY_prop', 'CSNY', 'DWSSHY_in_DWJJLX_prop', 'DWJJLX_DWSSHY_count', 'numsOf_GRJCJS_GRZHDNGJYE_diff', 'numsOf_GRZHDNGJYE_GRZHYE_diff_GRZHSNJZYE_div', 'GRJCJS_DKFFE_multi_DKLL_ratio_std', 'numsOf_GRZHDNGJYE_GRYJCE_div', 'numsOf_GRJCJS_GRZHDNGJYE_div', 'GRYJCE_GRJCJS_std', 'GRYJCE_GRJCJS_max', 'GRJCJS_DKFFE_DKY_multi_DKLL_std', 'GRZHZT_in_DWSSHY_prop', 'GRJCJS_GRZHDNGJYE_std', 'GRJCJS_YEARPURINCM_std', 'numsOf_GRZHDNGJYE_YEARPURINCM_div', 'GRZHZT_GRZHYE_mean', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE1_std', 'GRJCJS_HDSYYF_std', 'DWJJLX_GRZHDNGJYE_sum', 'GRJCJS_HDZYF_std', 'GRYJCE_DKFFE_DKY_multi_DKLL_std', 'numsOf_GRZHYE_GRZHDNGJYE_div', 'GRJCJS_HDYF_std', 'GRJCJS_DKYE_std', 'GRYJCE_GRZHYE_diff_GRZHDNGJYE_std', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE_std', 'GRJCJS_HDYF_mean', 'GRZHDNGJYE_GRJCJS_sum', 'numsOf_GRZHDNGJYE_GRZHSNJZYE_GRZHYE_diff_GRZHSNJZYE_div', 'numsOf_GRYJCE_HDZYF_add', 'GRYJCE_DKFFE_multi_DKLL_ratio_std', 'DWSSHY_GRZHZT_count', 'GRJCJS_DKFFE_std', 'GRJCJS_GRZHDNGJYE_mean', 'GRYJCE_YEARPURINCM_sum', 'GRYJCE_YEARPURINCM_std', 'GRYJCE_GRZHDNGJYE_mean', 'GRJCJS_GRZHYE_diff_GRZHSNJZYE_sum', 'GRJCJS_GRYJCE_min', 'GRYJCE_GRZHDNGJYE_std', 'GRYJCE_GRZHYE_diff_GRZHSNJZYE_std', 'GRYJCE_YEARPURINCM_mean', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE2_std', 'DWJJLX_8', 'GRJCJS_DKLL_std', 'numsOf_GRZHSNJZYE_GRZHDNGJYE_div', 'DWSSHY_DKFFE_multi_DKLL_ratio_mean', 'GRJCJS_GRZHYE_diff_GRZHDNGJYE_std', 'GRYJCE_HDYF_min', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE1_mean', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE_std', 'GRJCJS_GRYJCE_std', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_YEARPURINCM_div', 'GRYJCE_HDYF_std', 'GRYJCE_HDZYF_min', 'GRJCJS_GRZHYE_diff_GRZHDNGJYE_min', 'GRJCJS_GRZHDNGJYE_max', 'GRYJCE_DKLL_std', 'GRYJCE_GRZHDNGJYE_sum', 'DWSSHY_DKFFE_genFeat3_mean', 'GRYJCE_DKFFE_DKYE_std', 'GRJCJS_GRZHYE_std', 'GRJCJS_DKFFE_DKYE_std', 'numsOf_GRYJCE_HDSYYF_add', 'GRJCJS_YEARPURINCM_sum', 'age', 'GRJCJS_HDZYF_min', 'GRJCJS_GRZHSNJZYE_std', 'numsOf_GRZHDNGJYE_GRZHSNJZYE2_YEARPURINCM_div', 'GRJCJS_GRZHYE_diff_GRZHSNJZYE_mean', 'GRJCJS_GRZHYE_diff_GRZHSNJZYE_max', 'numsOf_GRZHDNGJYE_GRZHSNJZYE_GRZHYE_diff_GRZHDNGJYE_div', 'GRJCJS_HDZYFZE_std', 'numsOf_GRJCJS_GRZHYE_diff_GRZHSNJZYE_div', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE1_std', 'GRJCJS_YEARPURINCM_mean', 'GRYJCE_HDSYYF_std', 'GRYJCE_DKFFE_std', 'GRYJCE_GRZHYE_std', 'GRYJCE_HDYF_mean', 'numsOf_GRYJCE_GRZHYE_diff_GRZHSNJZYE_div', 'HDZYF_HDYF_mean', 'GRYJCE_GRZHSNJZYE_std', 'GRJCJS_YEARPURINCM_max', 'numsOf_DKLL_DKFFE_multi_DKLL_ratio_add', 'numsOf_GRZHDNGJYE_GRZHSNJZYE2_GRZHYE_diff_GRZHSNJZYE_div', 'GRYJCE_HDZYF_std', 'GRYJCE_GRZHYE_diff_GRZHSNJZYE_max', 'GRJCJS_HDYF_min', 'GRJCJS_HDZYF_max', 'numsOf_GRZHDNGJYE_HDZYF_multi', 'GRJCJS_DKYE_mean', 'GRJCJS_DKFFE_DKY_multi_DKLL_mean', 'GRYJCE_GRZHYE_diff_GRZHSNJZYE_mean', 'numsOf_GRZHYE_diff_GRZHDNGJYE_HDYF_multi', 'numsOf_GRZHYE_GRZHDNGJYE_GRZHSNJZYE1_div', 'numsOf_GRZHYE_diff_GRZHSNJZYE_YEARPURINCM_div', 'GRYJCE_GRZHYE_diff_GRZHSNJZYE_sum', 'GRYJCE_GRZHYE_diff_GRZHDNGJYE_min', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE1_mean', 'HDZYFZE_HDYF_std', 'numsOf_DKLL_DKFFE_multi_DKLL_ratio_diff', 'DWSSHY_YEARPURINCM_min', 'GRYJCE_GRZHDNGJYE_max', 'GRZHDNGJYE_HDYF_min', 'DWSSHY_HDYF_max', 'GRJCJS_DKFFE_mean', 'GRYJCE_DKYE_std', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE1_max', 'numsOf_GRZHDNGJYE_GRZHYE_diff_GRZHSNJZYE_multi', 'HDZYFZE_DKFFE_multi_DKLL_ratio_std', 'GRZHDNGJYE_GRYJCE_std', 'numsOf_GRZHYE_GRZHDNGJYE_GRZHSNJZYE_div', 'GRYJCE_GRJCJS_sum', 'HDZYF_HDSYYF_std', 'GRJCJS_GRZHYE_diff_GRZHSNJZYE_min', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE_std', 'numsOf_DKFFE_multi_DKLL_ratio_GRZHYE_diff_GRZHSNJZYE_div', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE2_std', 'numsOf_GRZHDNGJYE_HDSYYF_multi', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE_mean', 'numsOf_GRJCJS_GRZHDNGJYE_GRZHSNJZYE_div', 'numsOf_GRJCJS_HDSYYF_multi', 'numsOf_DKYE_GRZHDNGJYE_GRZHSNJZYE1_div', 'numsOf_GRZHYE_YEARPURINCM_div', 'GRJCJS_HDSYYFZE_std', 'GRJCJS_GRZHDNGJYE_sum', 'GRZHDNGJYE_HDZYF_min', 'numsOf_GRJCJS_YEARPURINCM_div', 'GRYJCE_YEARPURINCM_max', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE2_mean', 'GRZHZT_in_DWJJLX_prop', 'GRYJCE_HDZYFZE_std', 'GRJCJS_YEARPURINCM_min', 'GRZHDNGJYE_DKFFE_std', 'GRJCJS_DKLL_mean', 'GRJCJS_GRZHYE_mean', 'DWSSHY_DKYE_mean', 'numsOf_GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE2_div', 'GRYJCE_GRZHDNGJYE_min', 'HDZYF_HDYF_min', 'numsOf_GRZHYE_GRZHDNGJYE_GRZHSNJZYE2_div', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE_min', 'HDZYF_GRJCJS_max', 'GRJCJS_GRZHYE_diff_GRZHSNJZYE_std', 'GRJCJS_GRYJCE_sum', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE1_std', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_GRZHDNGJYE_GRZHSNJZYE2_div', 'GRZHDNGJYE_DKLL_std', 'numsOf_GRJCJS_GRZHDNGJYE_GRZHSNJZYE1_div', 'DWJJLX_GRZHZT_count', 'GRJCJS_HDYF_sum', 'DWSSHY_GRJCJS_min', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_HDYF_multi', 'numsOf_GRZHYE_GRZHYE_diff_GRZHSNJZYE_div', 'HDZYF_YEARPURINCM_sum', 'numsOf_GRYJCE_HDYF_add', 'DWJJLX_DKFFE_genFeat7_mean', 'numsOf_GRZHYE_HDYF_multi', 'GRYJCE_HDYF_max', 'HDZYFZE_GRZHDNGJYE_mean', 'HDZYF_GRZHDNGJYE_std', 'GRYJCE_YEARPURINCM_min', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE2_min', 'GRJCJS_DKFFE_DKYE_mean', 'DWSSHY_HDZYF_min', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE_min', 'GRJCJS_GRZHSNJZYE_min', 'GRZHDNGJYE_HDZYFZE_std', 'GRZHDNGJYE_GRZHYE_diff_GRZHSNJZYE_std', 'HDZYF_GRZHDNGJYE_sum', 'GRYJCE_GRZHYE_diff_GRZHDNGJYE_max', 'numsOf_GRZHSNJZYE_HDYF_multi', 'numsOf_GRZHDNGJYE_GRZHSNJZYE_HDYF_multi', 'numsOf_DKYE_GRZHYE_diff_GRZHSNJZYE_div', 'numsOf_GRJCJS_DKFFE_multi_DKLL_ratio_div', 'numsOf_GRJCJS_DKYE_multi_DKLL_ratio_multi', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_HDYF_div', 'DWJJLX_DKLL_std', 'HDZYFZE_GRJCJS_std', 'numsOf_DKFFE_HDZYF_multi', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE1_max', 'HDZYF_GRJCJS_sum', 'GRYJCE_DKFFE_DKY_multi_DKLL_mean', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_GRZHYE_diff_GRZHSNJZYE_div', 'DWSSHY_DKFFE_genFeat1_mean', 'numsOf_YEARPURINCM_HDZYF_multi', 'numsOf_GRZHYE_diff_GRZHDNGJYE_HDZYF_multi', 'GRJCJS_DKFFE_multi_DKLL_ratio_sum', 'GRJCJS_DKFFE_DKYE_min', 'numsOf_GRZHYE_diff_GRZHDNGJYE_GRZHYE_diff_GRZHSNJZYE_div', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE_mean', 'GRZHDNGJYE_DKFFE_multi_DKLL_ratio_std', 'HDZYF_DKFFE_multi_DKLL_ratio_sum', 'numsOf_GRZHSNJZYE_YEARPURINCM_div', 'numsOf_GRYJCE_YEARPURINCM_div', 'GRJCJS_GRZHYE_max', 'numsOf_GRZHSNJZYE_GRZHYE_diff_GRZHDNGJYE_div', 'HDZYF_GRZHYE_std', 'GRYJCE_HDYF_sum', 'DWSSHY_GRJCJS_mean', 'GRJCJS_HDSYYF_max', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE_min', 'HDZYF_GRYJCE_sum', 'numsOf_GRZHSNJZYE_GRZHDNGJYE_GRZHSNJZYE1_div', 'DWSSHY_GRZHYE_diff_GRZHSNJZYE_max', 'DWSSHY_DKYE_genFeat1_mean', 'numsOf_DKLL_YEARPURINCM_div', 'DKFFE_DKLL_std', 'GRJCJS_HDZYF_sum', 'DWSSHY_GRZHYE_diff_GRZHSNJZYE_sum', 'GRYJCE_DKLL_mean', 'GRYJCE_DKFFE_mean', 'GRYJCE_GRZHSNJZYE_mean', 'numsOf_YEARPURINCM_HDSYYF_multi', 'numsOf_GRYJCE_GRZHYE_diff_GRZHDNGJYE_div', 'numsOf_YEARPURINCM_HDYF_multi', 'numsOf_DKLL_GRZHYE_diff_GRZHSNJZYE_div', 'GRJCJS_GRZHYE_min', 'numsOf_GRZHDNGJYE_YEARPURINCM_multi', 'HDZYF_YEARPURINCM_max', 'numsOf_GRYJCE_GRZHDNGJYE_GRZHSNJZYE1_div', 'numsOf_GRJCJS_GRZHYE_diff_GRZHDNGJYE_add', 'numsOf_DKYE_multi_DKLL_ratio_GRZHYE_diff_GRZHSNJZYE_div', 'GRZHDNGJYE_HDYF_mean', 'GRZHDNGJYE_GRYJCE_max', 'HDZYF_DKFFE_multi_DKLL_ratio_std', 'DWSSHY_DKYE_genFeat7_mean', 'DWSSHY_DKYE_max', 'GRYJCE_GRZHSNJZYE_min', 'HDZYFZE_HDYF_mean', 'DWJJLX_DKYE_genFeat7_mean', 'HDZYFZE_GRZHYE_std', 'HDZYF_YEARPURINCM_std', 'numsOf_GRJCJS_GRZHYE_diff_GRZHDNGJYE_div', 'numsOf_GRZHYE_diff_GRZHDNGJYE_HDYF_div', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE2_std', 'DWSSHY_GRZHYE_max', 'numsOf_GRZHYE_diff_GRZHSNJZYE_YEARPURINCM_multi', 'GRJCJS_GRZHSNJZYE_mean', 'numsOf_GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE_multi', 'HDZYF_DKYE_multi_DKLL_ratio_max', 'HDZYF_HDYF_max', 'GRJCJS_HDSYYF_mean', 'GRYJCE_HDSYYF_min', 'GRYJCE_GRZHYE_mean', 'DWSSHY_GRZHDNGJYE_max', 'numsOf_GRZHDNGJYE_GRZHSNJZYE2_GRZHYE_diff_GRZHDNGJYE_div', 'DKFFE_HDYF_std', 'numsOf_GRZHSNJZYE_GRYJCE_div', 'GRYJCE_DKFFE_DKYE_mean', 'HDZYF_YEARPURINCM_mean', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE_sum', 'numsOf_GRZHYE_diff_GRZHSNJZYE_HDYF_div', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE1_min', 'numsOf_GRJCJS_DKFFE_DKYE_multi', 'GRJCJS_GRZHYE_diff_GRZHDNGJYE_max', 'numsOf_GRZHYE_diff_GRZHSNJZYE_HDSYYF_multi', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE2_min', 'DWSSHY_GRZHDNGJYE_mean', 'GRJCJS_HDYF_max', 'GRJCJS_DKFFE_DKY_multi_DKLL_max', 'DWSSHY_GRZHSNJZYE_max', 'DWSSHY_GRZHYE_diff_GRZHDNGJYE_min', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE1_min', 'numsOf_DKFFE_DKFFE_multi_DKLL_ratio_multi', 'numsOf_GRJCJS_YEARPURINCM_diff', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE1_max', 'GRZHDNGJYE_GRJCJS_max', 'DWSSHY_GRJCJS_std', 'DWSSHY_DKYE_genFeat3_mean', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE_max', 'GRYJCE_HDZYF_max', 'HDZYF_GRJCJS_std', 'GRYJCE_GRZHYE_max', 'GRJCJS_HDSYYF_min', 'HDZYF_GRZHDNGJYE_mean', 'numsOf_DKYE_YEARPURINCM_div', 'DKFFE_multi_DKLL_ratio_HDYF_sum', 'HDZYFZE_YEARPURINCM_mean', 'GRYJCE_DKFFE_multi_DKLL_ratio_sum', 'DWSSHY_GRZHDNGJYE_GRZHSNJZYE_min', 'GRZHZT', 'numsOf_DKFFE_HDYF_multi', 'GRZHDNGJYE_HDYF_std', 'DKFFE_GRYJCE_std', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_HDSYYF_multi', 'HDZYF_HDSYYF_min', 'GRJCJS_DKFFE_multi_DKLL_ratio_mean', 'HDZYF_GRZHYE_diff_GRZHDNGJYE_max', 'numsOf_GRZHDNGJYE_YEARPURINCM_diff', 'numsOf_DKLL_GRZHDNGJYE_GRZHSNJZYE1_div', 'numsOf_DKFFE_DKY_multi_DKLL_HDZYF_div', 'GRJCJS_DKYE_multi_DKLL_ratio_mean', 'DWSSHY_HDZYF_mean', 'GRJCJS_DKFFE_DKY_multi_DKLL_min', 'numsOf_DKFFE_multi_DKLL_ratio_HDZYFZE_multi', 'numsOf_GRZHYE_GRZHYE_diff_GRZHDNGJYE_div', 'DKYE_multi_DKLL_ratio_GRJCJS_std', 'numsOf_DKFFE_DKYE_GRZHDNGJYE_GRZHSNJZYE1_div', 'GRYJCE_HDSYYFZE_std', 'numsOf_GRZHSNJZYE_GRZHYE_diff_GRZHSNJZYE_div', 'GRYJCE_DKFFE_multi_DKLL_ratio_min', 'GRZHDNGJYE_DKFFE_DKYE_std', 'numsOf_GRZHYE_diff_GRZHSNJZYE_HDYF_multi', 'DKFFE_DKY_multi_DKLL_YEARPURINCM_sum', 'HDZYF_GRZHYE_diff_GRZHSNJZYE_std', 'numsOf_DKFFE_DKYE_multi_DKLL_ratio_div', 'DWJJLX_YEARPURINCM_mean', 'HDZYF_GRZHYE_diff_GRZHSNJZYE_mean', 'DWSSHY_GRZHDNGJYE_GRZHSNJZYE2_min', 'DWSSHY_HDZYF_std', 'GRYJCE_DKFFE_multi_DKLL_ratio_mean', 'GRZHDNGJYE_GRYJCE_sum', 'GRYJCE_GRZHYE_diff_GRZHSNJZYE_min', 'GRYJCE_HDSYYF_sum', 'DWJJLX_DKLL_mean', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_GRZHYE_diff_GRZHSNJZYE_add', 'numsOf_GRJCJS_HDZYF_multi', 'numsOf_DKFFE_multi_DKLL_ratio_HDZYF_multi', 'DWSSHY_GRZHDNGJYE_GRZHSNJZYE2_std', 'DKFFE_YEARPURINCM_sum', 'HDZYF_DKYE_std', 'numsOf_DKFFE_DKYE_GRZHYE_diff_GRZHSNJZYE_div', 'DWSSHY_DKLL_mean', 'DWSSHY_GRZHDNGJYE_min', 'GRYJCE_DKFFE_DKYE_min', 'HDZYF_GRZHDNGJYE_max', 'HDZYFZE_GRZHYE_diff_GRZHDNGJYE_min', 'DKFFE_multi_DKLL_ratio_GRJCJS_mean', 'numsOf_DKYE_multi_DKLL_ratio_YEARPURINCM_div', 'GRZHDNGJYE_GRZHYE_diff_GRZHDNGJYE_min', 'HDZYF_GRZHYE_diff_GRZHSNJZYE_sum', 'HDZYFZE_YEARPURINCM_std', 'numsOf_HDSYYF_HDYF_multi', 'DWSSHY', 'DWSSHY_DKLL_std', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE2_mean', 'numsOf_GRJCJS_GRZHDNGJYE_add', 'GRYJCE_HDSYYF_mean', 'DKFFE_YEARPURINCM_max', 'GRJCJS_DKFFE_multi_DKLL_ratio_min', 'numsOf_GRJCJS_HDSYYF_add', 'GRYJCE_HDZYF_mean', 'HDZYF_GRZHSNJZYE_std', 'DWJJLX_DKFFE_mean', 'HDZYF_DKYE_multi_DKLL_ratio_mean', 'GRZHDNGJYE_GRYJCE_min', 'HDZYF_GRZHDNGJYE_min', 'numsOf_GRZHYE_GRZHSNJZYE_div', 'HDZYF_GRZHYE_diff_GRZHSNJZYE_min', 'numsOf_GRJCJS_GRZHYE_div', 'HDZYF_DKFFE_multi_DKLL_ratio_mean', 'GRJCJS_GRZHSNJZYE_max', 'HDZYF_GRZHYE_diff_GRZHDNGJYE_std', 'HDZYF_GRZHYE_sum', 'HDSYYFZE_DKFFE_multi_DKLL_ratio_sum', 'numsOf_DKYE_HDYF_multi', 'numsOf_GRZHSNJZYE_HDYF_div', 'DKFFE_multi_DKLL_ratio_GRZHDNGJYE_std', 'numsOf_GRZHYE_diff_GRZHDNGJYE_YEARPURINCM_div', 'GRZHDNGJYE_GRZHYE_std', 'DKFFE_GRJCJS_std', 'GRYJCE_DKYE_multi_DKLL_ratio_sum', 'DKFFE_DKLL_mean', 'numsOf_GRZHDNGJYE_HDYF_multi', 'DKYE_GRYJCE_std', 'DKYE_DKLL_mean', 'DKYE_DKFFE_multi_DKLL_ratio_sum', 'GRZHYE_HDSYYF_min', 'numsOf_GRZHDNGJYE_DKYE_multi', 'DKFFE_multi_DKLL_ratio_GRZHDNGJYE_max', 'numsOf_HDZYF_HDYF_multi', 'numsOf_HDZYF_HDZYFZE_multi', 'numsOf_DKYE_HDZYFZE_diff', 'numsOf_DKFFE_GRZHYE_diff_GRZHSNJZYE_div', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_GRZHYE_diff_GRZHDNGJYE_div', 'numsOf_DKYE_HDZYF_div', 'numsOf_GRJCJS_GRZHYE_diff', 'GRYJCE_GRZHYE_diff_GRZHDNGJYE_mean', 'GRZHDNGJYE_DKYE_std', 'HDZYF_GRZHYE_diff_GRZHDNGJYE_min', 'numsOf_GRYJCE_DKFFE_DKYE_multi', 'GRYJCE_DKYE_mean', 'HDSYYFZE_GRYJCE_std', 'HDZYF_HDSYYF_sum', 'GRYJCE_DKFFE_DKYE_max', 'HDZYF_DKYE_multi_DKLL_ratio_sum', 'numsOf_GRYJCE_DKFFE_multi_DKLL_ratio_div', 'numsOf_GRZHDNGJYE_HDYF_div', 'GRJCJS_GRZHDNGJYE_min', 'HDZYFZE_DKFFE_multi_DKLL_ratio_mean', 'DWSSHY_GRZHDNGJYE_std', 'DWSSHY_GRZHDNGJYE_GRZHSNJZYE1_max', 'numsOf_GRZHSNJZYE_GRZHYE_diff_GRZHSNJZYE_diff', 'GRJCJS_GRZHYE_sum', 'GRJCJS_DKYE_max', 'DKFFE_DKY_multi_DKLL_GRYJCE_std', 'DKFFE_DKYE_GRZHDNGJYE_GRZHSNJZYE1_std', 'numsOf_GRZHYE_HDZYF_multi', 'DKFFE_DKFFE_multi_DKLL_ratio_std', 'GRZHZT_count', 'numsOf_GRZHSNJZYE_GRZHDNGJYE_GRZHSNJZYE_div', 'numsOf_GRZHDNGJYE_GRZHSNJZYE2_HDYF_multi', 'HDZYF_YEARPURINCM_min', 'GRYJCE_GRZHYE_sum', 'GRJCJS_DKYE_min', 'GRYJCE_GRZHYE_min', 'GRZHDNGJYE_HDSYYF_min', 'numsOf_GRZHDNGJYE_GRZHSNJZYE_YEARPURINCM_diff', 'GRZHDNGJYE_HDSYYF_std', 'GRZHDNGJYE_YEARPURINCM_max', 'GRYJCE_DKYE_max', 'numsOf_DKFFE_multi_DKLL_ratio_YEARPURINCM_div', 'GRJCJS_HDZYFZE_mean', 'GRJCJS_HDSYYFZE_mean', 'GRYJCE_GRZHSNJZYE_max', 'DKFFE_GRZHYE_std', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE2_mean', 'numsOf_YEARPURINCM_HDYF_div', 'XINGBIE', 'HDZYFZE_GRZHYE_diff_GRZHSNJZYE_mean', 'numsOf_GRJCJS_HDYF_multi', 'numsOf_GRZHSNJZYE_GRZHDNGJYE_GRZHSNJZYE2_div', 'numsOf_GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE1_multi', 'numsOf_GRZHYE_HDSYYF_multi', 'DWSSHY_GRYJCE_min', 'DWSSHY_DKFFE_DKYE_std', 'numsOf_GRZHSNJZYE_YEARPURINCM_diff', 'DWSSHY_GRZHDNGJYE_GRZHSNJZYE1_min', 'numsOf_GRJCJS_GRZHSNJZYE_diff', 'numsOf_DKFFE_DKYE_HDZYF_multi', 'numsOf_GRJCJS_YEARPURINCM_add', 'DWSSHY_HDYF_std', 'numsOf_GRZHDNGJYE_GRZHSNJZYE1_YEARPURINCM_multi', 'DWSSHY_DKYE_multi_DKLL_ratio_mean', 'numsOf_GRJCJS_GRZHYE_add', 'HDZYF_GRZHYE_min', 'DWSSHY_GRZHYE_diff_GRZHSNJZYE_mean', 'HDZYF_HDYF_sum', 'DWSSHY_GRZHDNGJYE_sum', 'numsOf_GRZHYE_HDZYF_div', 'DWSSHY_count', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE_sum', 'DKFFE_GRZHSNJZYE_min', 'numsOf_DKYE_multi_DKLL_ratio_HDZYFZE_div', 'HDZYF_DKFFE_DKYE_min', 'numsOf_DKFFE_YEARPURINCM_multi', 'HDZYFZE_GRZHSNJZYE_mean', 'GRZHDNGJYE_HDZYF_std', 'numsOf_HDYF_HDZYFZE_div', 'GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE1_mean', 'numsOf_DKLL_GRZHDNGJYE_GRZHSNJZYE_div', 'GRYJCE_GRZHDNGJYE_GRZHSNJZYE_max', 'GRYJCE_DKYE_min', 'numsOf_GRZHDNGJYE_GRZHSNJZYE_HDSYYF_multi', 'GRZHYE_GRZHYE_diff_GRZHDNGJYE_sum', 'DKFFE_DKY_multi_DKLL_YEARPURINCM_std', 'GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE1_max', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE1_mean', 'GRJCJS_HDSYYF_sum', 'DKFFE_DKY_multi_DKLL_GRZHDNGJYE_max', 'GRJCJS_HDZYF_mean', 'GRZHDNGJYE_YEARPURINCM_sum', 'HDZYFZE_DKFFE_multi_DKLL_ratio_min', 'HDZYF_GRZHDNGJYE_GRZHSNJZYE2_min', 'GRJCJS_GRZHYE_diff_GRZHDNGJYE_mean', 'GRJCJS_GRZHYE_diff_GRZHDNGJYE_sum', 'HDZYFZE_GRZHDNGJYE_GRZHSNJZYE2_min', 'GRZHYE_HDZYF_min', 'DKFFE_DKYE_GRJCJS_std', 'DWSSHY_GRYJCE_std', 'DKFFE_DKYE_HDZYF_std', 'numsOf_GRZHYE_diff_GRZHDNGJYE_HDSYYF_div', 'HDZYF_GRZHYE_max', 'GRYJCE_HDSYYFZE_max', 'GRYJCE_DKYE_multi_DKLL_ratio_max', 'GRYJCE_GRZHSNJZYE_sum', 'numsOf_GRZHDNGJYE_GRZHYE_diff_GRZHDNGJYE_div', 'HDZYF_DKFFE_DKY_multi_DKLL_min', 'DKFFE_DKY_multi_DKLL_GRJCJS_mean', 'numsOf_DKFFE_DKY_multi_DKLL_YEARPURINCM_div', 'HDZYFZE_HDSYYF_std', 'DKFFE_DKYE_YEARPURINCM_sum', 'HDZYFZE_HDYF_max', 'GRJCJS_DKFFE_min', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE1_sum', 'numsOf_GRJCJS_GRZHDNGJYE_GRZHSNJZYE_diff', 'numsOf_DKYE_GRZHDNGJYE_GRZHSNJZYE_div', 'numsOf_GRJCJS_DKFFE_DKY_multi_DKLL_multi', 'numsOf_GRJCJS_GRZHYE_diff_GRZHDNGJYE_diff', 'numsOf_DKFFE_YEARPURINCM_div', 'numsOf_GRZHYE_diff_GRZHDNGJYE_HDZYF_div', 'GRJCJS_GRZHDNGJYE_GRZHSNJZYE2_max', 'numsOf_DKFFE_GRZHYE_diff_GRZHDNGJYE_multi', 'DKYE_multi_DKLL_ratio_HDYF_std', 'GRYJCE_DKFFE_DKY_multi_DKLL_max', 'DKFFE_multi_DKLL_ratio_GRZHYE_diff_GRZHSNJZYE_std', 'DKFFE_multi_DKLL_ratio_GRZHYE_diff_GRZHSNJZYE_sum', 'DKFFE_DKY_multi_DKLL_DKFFE_multi_DKLL_ratio_sum', 'DKFFE_DKYE_YEARPURINCM_std', 'numsOf_GRYJCE_GRZHDNGJYE_GRZHSNJZYE_div', 'DKFFE_HDZYFZE_std', 'numsOf_GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE1_div', 'numsOf_GRZHYE_HDZYFZE_add', 'numsOf_GRZHSNJZYE_GRZHDNGJYE_GRZHSNJZYE1_multi', 'numsOf_GRZHDNGJYE_GRZHDNGJYE_GRZHSNJZYE_div', 'GRZHYE_GRJCJS_sum', 'DKFFE_DKY_multi_DKLL_HDYF_sum', 'HDZYF_DKFFE_DKYE_std', 'HDSYYFZE_GRZHYE_diff_GRZHSNJZYE_min']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in dImp[dImp.importance>20].column.values.tolist()  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(dImp[dImp['importance']<1]['column'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['id'] = test_df['id']\n",
    "submit['label'] = test_df['prob']\n",
    "submit = pd.merge(test,submit,on='id',how='left')[['id','label']]\n",
    "submit['label'] = submit['label'].apply(lambda x: 0 if pd.isnull(x) else x)\n",
    "\n",
    "\n",
    "submit.to_csv('../sub/submission{}_{}.csv'.format(tpr, round(np.mean(val_aucs), 6)), index = False)\n",
    "submit.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
